<div class="ocaml_toplevel_module"><div class="info">Threading model:<p>    Only one thread is running Async code at a time.  This is enforced by a single lock in
    Async's scheduler data structure.  There are any number of threads running code
    without holding the lock that get data from the outside world and want to affect the
    Async world.  They do this by calling <code class="code">Thread_safe.run_in_async*</code>, which acquires the
    lock, does a computation (e.g. fills an ivar), and then runs a &quot;cycle&quot; of Async
    computations.</p></div>
<pre><span class="TYPEt"><span class="keyword">type</span> t</span> = <code class="type"><a href="?package=async_unix&amp;module=Raw_scheduler&amp;type=t">Raw_scheduler.t</a></code></pre>
<pre><span class="VALt"><span class="keyword">val</span> t</span> : <code class="type">unit -&gt; <a href="?package=async_unix&amp;module=Scheduler&amp;type=t">t</a></code></pre><div class="info"><div class="info"><code class="code">t ()</code> returns the async scheduler.  If the scheduler hasn't been created yet, this
    will create it and acquire the async lock.</div></div>
<pre><span class="VALgo"><span class="keyword">val</span> go</span> : <code class="type">?raise_unhandled_exn:bool -&gt; unit -&gt; <a href="?package=core&amp;module=Std&amp;type=never_returns">Core.Std.never_returns</a></code></pre><div class="info"><div class="info"><code class="code">go ?raise_unhandled_exn ()</code> passes control to Async, at which point Async starts
    running handlers, one by one without interruption, until there are no more handlers to
    run.  When Async is out of handlers it blocks until the outside world schedules more
    of them.  Because of this, Async programs do not exit until <code class="code">shutdown</code> is called.<p>    <code class="code">go ()</code> calls <code class="code">handle_signal Sys.sigpipe</code>, which causes the SIGPIPE signal to be
    ignored.  Low-level syscalls (e.g. write) still raise EPIPE.</p><p>    If any async job raises an unhandled exception that is not handled by any monitor,
    async execution ceases.  Then, by default, async pretty prints the exception, and
    exits with status 1.  If you don't want this, pass <code class="code">~raise_unhandled_exn:true</code>, which
    will cause the unhandled exception to be raised to the caller of <code class="code">go ()</code>.</p></div></div>
<pre><span class="VALgo_main"><span class="keyword">val</span> go_main</span> : <code class="type">?raise_unhandled_exn:bool -&gt;
?file_descr_watcher:<a href="?package=async_unix&amp;module=Import.Config.File_descr_watcher&amp;type=t">Import.Config.File_descr_watcher.t</a> -&gt;
?max_num_open_file_descrs:int -&gt;
?max_num_threads:int -&gt; main:(unit -&gt; unit) -&gt; unit -&gt; <a href="?package=core&amp;module=Std&amp;type=never_returns">Core.Std.never_returns</a></code></pre><div class="info"><div class="info"><code class="code">go_main</code> is like <code class="code">go</code>, except that one supplies a <code class="code">main</code> function that will be run to
    initialize the async computation, and that <code class="code">go_main</code> will fail if any async has been
    used prior to <code class="code">go_main</code> being called.  Moreover it allows to configure more static
    options of the scheduler.</div></div>
<pre><span class="TYPEwith_options"><span class="keyword">type</span> <code class="type">'a </code>with_options</span> = <code class="type">?monitor:<a href="?package=async_unix&amp;module=Import.Monitor&amp;type=t">Import.Monitor.t</a> -&gt; ?priority:<a href="?package=async_unix&amp;module=Import.Priority&amp;type=t">Import.Priority.t</a> -&gt; 'a</code></pre>
<pre><span class="VALwithin_context"><span class="keyword">val</span> within_context</span> : <code class="type"><a href="?package=async_unix&amp;module=Import.Execution_context&amp;type=t">Import.Execution_context.t</a> -&gt; (unit -&gt; 'a) -&gt; ('a, unit) <a href="?package=core&amp;module=Std.Result&amp;type=t">Core.Std.Result.t</a></code></pre><div class="info"><div class="info"><code class="code">within_context context f</code> runs <code class="code">f ()</code> right now with the specified execution
    context.  If <code class="code">f</code> raises, then the exception is sent to the monitor of <code class="code">context</code>, and
    <code class="code">Error ()</code> is returned.</div></div>
<pre><span class="VALwithin'"><span class="keyword">val</span> within'</span> : <code class="type">((unit -&gt; 'a <a href="?package=async_unix&amp;module=Import.Deferred&amp;type=t">Import.Deferred.t</a>) -&gt; 'a <a href="?package=async_unix&amp;module=Import.Deferred&amp;type=t">Import.Deferred.t</a>) <a href="?package=async_unix&amp;module=Scheduler&amp;type=with_options">with_options</a></code></pre><div class="info"><div class="info"><code class="code">within' f ~monitor ~priority</code> runs <code class="code">f ()</code> right now, with the specified
    block group, monitor, and priority set as specified.  They will be reset to their
    original values when <code class="code">f</code> returns.  If <code class="code">f</code> raises, then the result of <code class="code">within'</code> will
    never become determined, but the exception will end up in the specified monitor.</div></div>
<pre><span class="VALwithin"><span class="keyword">val</span> within</span> : <code class="type">((unit -&gt; unit) -&gt; unit) <a href="?package=async_unix&amp;module=Scheduler&amp;type=with_options">with_options</a></code></pre><div class="info"><div class="info"><code class="code">within</code> is like <code class="code">within'</code>, but doesn't require thunk to return a deferred.</div></div>
<pre><span class="VALwithin_v"><span class="keyword">val</span> within_v</span> : <code class="type">((unit -&gt; 'a) -&gt; 'a option) <a href="?package=async_unix&amp;module=Scheduler&amp;type=with_options">with_options</a></code></pre><div class="info"><div class="info"><code class="code">within_v</code> is like <code class="code">within</code>, but allows a value to be returned by <code class="code">f</code>.</div></div>
<pre><span class="VALwith_local"><span class="keyword">val</span> with_local</span> : <code class="type">'a <a href="?package=core&amp;module=Std.Univ_map.Key&amp;type=t">Core.Std.Univ_map.Key.t</a> -&gt; 'a option -&gt; f:(unit -&gt; 'b) -&gt; 'b</code></pre><div class="info"><div class="info"><code class="code">with_local key value ~f</code> runs <code class="code">f</code> right now with the binding <code class="code">key = value</code>.  All
    calls to <code class="code">find_local key</code> in <code class="code">f</code> and computations started from <code class="code">f</code> will return
    <code class="code">value</code>.</div></div>
<pre><span class="VALfind_local"><span class="keyword">val</span> find_local</span> : <code class="type">'a <a href="?package=core&amp;module=Std.Univ_map.Key&amp;type=t">Core.Std.Univ_map.Key.t</a> -&gt; 'a option</code></pre><div class="info"><div class="info"><code class="code">find_local key</code> returns the value associated to <code class="code">key</code> in the current execution
    context.</div></div>
<pre><span class="VALschedule'"><span class="keyword">val</span> schedule'</span> : <code class="type">((unit -&gt; 'a <a href="?package=async_unix&amp;module=Import.Deferred&amp;type=t">Import.Deferred.t</a>) -&gt; 'a <a href="?package=async_unix&amp;module=Import.Deferred&amp;type=t">Import.Deferred.t</a>) <a href="?package=async_unix&amp;module=Scheduler&amp;type=with_options">with_options</a></code></pre><div class="info"><div class="info">Just like <code class="code">within'</code>, but instead of running thunk right now, adds
    it to the async queue to be run with other async jobs.</div></div>
<pre><span class="VALschedule"><span class="keyword">val</span> schedule</span> : <code class="type">((unit -&gt; unit) -&gt; unit) <a href="?package=async_unix&amp;module=Scheduler&amp;type=with_options">with_options</a></code></pre><div class="info"><div class="info">Just like schedule', but doesn't require thunk to return a deferred.</div></div>
<pre><span class="VALpreserve_execution_context"><span class="keyword">val</span> preserve_execution_context</span> : <code class="type">('a -&gt; unit) -&gt; ('a -&gt; unit) <a href="?package=core&amp;module=Std.Staged&amp;type=t">Core.Std.Staged.t</a></code></pre><div class="info"><div class="info"><code class="code">preserve_execution_context t f</code> saves the current execution context and returns a
    function <code class="code">g</code> such that <code class="code">g a</code> runs <code class="code">f a</code> in the saved execution context.  <code class="code">g a</code> becomes
    determined when <code class="code">f a</code> becomes determined.</div></div>
<pre><span class="VALpreserve_execution_context'"><span class="keyword">val</span> preserve_execution_context'</span> : <code class="type">('a -&gt; 'b <a href="?package=async_unix&amp;module=Import.Deferred&amp;type=t">Import.Deferred.t</a>) -&gt;
('a -&gt; 'b <a href="?package=async_unix&amp;module=Import.Deferred&amp;type=t">Import.Deferred.t</a>) <a href="?package=core&amp;module=Std.Staged&amp;type=t">Core.Std.Staged.t</a></code></pre>
<pre><span class="VALcycle_start"><span class="keyword">val</span> cycle_start</span> : <code class="type">unit -&gt; <a href="?package=core&amp;module=Std.Time&amp;type=t">Core.Std.Time.t</a></code></pre><div class="info"><div class="info"><code class="code">cycle_start ()</code> returns the result of <code class="code">Time.now ()</code> called at the beginning of
    cycle.</div></div>
<pre><span class="VALcycle_times"><span class="keyword">val</span> cycle_times</span> : <code class="type">unit -&gt; <a href="?package=core&amp;module=Std.Time.Span&amp;type=t">Core.Std.Time.Span.t</a> <a href="?package=async_unix&amp;module=Import.Stream&amp;type=t">Import.Stream.t</a></code></pre><div class="info"><div class="info"><code class="code">cycle_times ()</code> returns a stream that will have one element for each cycle that Async
    runs, with the amount of time that the cycle took (as determined by calls to Time.now
    at the beginning and end of the cycle).</div></div>
<pre><span class="VALreport_long_cycle_times"><span class="keyword">val</span> report_long_cycle_times</span> : <code class="type">?cutoff:<a href="?package=core&amp;module=Std.Time.Span&amp;type=t">Core.Std.Time.Span.t</a> -&gt; unit -&gt; unit</code></pre><div class="info"><div class="info"><code class="code">report_long_cycle_times ?cutoff ()</code> sets up something that will print a warning to
    stderr whenever there is an async cycle that is too long, as specified by <code class="code">cutoff</code>,
    whose default is 1s.</div></div>
<pre><span class="VALcycle_count"><span class="keyword">val</span> cycle_count</span> : <code class="type">unit -&gt; int</code></pre><div class="info"><div class="info"><code class="code">cycle_count ()</code> returns the total number of async cycles that have happened.</div></div>
<pre><span class="VALforce_current_cycle_to_end"><span class="keyword">val</span> force_current_cycle_to_end</span> : <code class="type">unit -&gt; unit</code></pre><div class="info"><div class="info"><code class="code">force_current_cycle_to_end ()</code> causes no more normal priority jobs to run in the
    current cycle, and for the end-of-cycle jobs (i.e. writes) to run, and then for the
    cycle to end.</div></div>
<pre><span class="VALis_running"><span class="keyword">val</span> is_running</span> : <code class="type">unit -&gt; bool</code></pre><div class="info"><div class="info"><code class="code">is_running ()</code> returns true if the scheduler has been started.</div></div>
<pre><span class="VALset_max_num_jobs_per_priority_per_cycle"><span class="keyword">val</span> set_max_num_jobs_per_priority_per_cycle</span> : <code class="type">int -&gt; unit</code></pre><div class="info"><div class="info"><code class="code">set_max_num_jobs_per_priority_per_cycle int</code> sets the maximum number of jobs that
    will be done at each priority within each async cycle.  The default is <code class="code">500</code>.</div></div>
<pre><span class="VALset_max_inter_cycle_timeout"><span class="keyword">val</span> set_max_inter_cycle_timeout</span> : <code class="type"><a href="?package=core&amp;module=Std.Time.Span&amp;type=t">Core.Std.Time.Span.t</a> -&gt; unit</code></pre><div class="info"><div class="info"><code class="code">set_max_inter_cycle_timeout span</code> sets the maximum amount of time the scheduler will
    remain blocked (on epoll or select) between cycles.</div></div>
<pre><span class="VALset_check_invariants"><span class="keyword">val</span> set_check_invariants</span> : <code class="type">bool -&gt; unit</code></pre><div class="info"><div class="info"><code class="code">set_check_invariants do_check</code> sets whether async should check invariants of its
    internal data structures.  <code class="code">set_check_invariants true</code> can substantially slow down
    your program.</div></div>
<pre><span class="VALset_detect_invalid_access_from_thread"><span class="keyword">val</span> set_detect_invalid_access_from_thread</span> : <code class="type">bool -&gt; unit</code></pre><div class="info"><div class="info"><code class="code">set_detect_invalid_access_from_thread do_check</code> sets whether async routines should
    check if they are being accessed from some thread other than the thread currently
    holding the async lock, which is not allowed and can lead to very confusing
    behavior.</div></div>
<pre><span class="VALset_record_backtraces"><span class="keyword">val</span> set_record_backtraces</span> : <code class="type">bool -&gt; unit</code></pre><div class="info"><div class="info"><code class="code">set_record_backtraces do_record</code> sets whether async should keep in the execution
    context the history of stack backtraces (obtained via <code class="code">Backtrace.get</code>) that led to the
    current job.  If an async job has an unhandled exception, this backtrace history will
    be recorded in the exception.  In particular the history will appean in an unhandled
    exception that reaches the main monitor.  This can have a substantial performance
    impact, both in running time and space usage.</div></div>
<pre><code><span class="TYPEfolder"><span class="keyword">type</span> <code class="type">'b </code>folder</span> = {</code></pre><table class="typetable">
		    <tr><td align="left" valign="top"><code>  </code></td><td align="left" valign="top"><code><span class="TYPEELTfolder.folder">folder</span> : <code class="type">'a. 'b -&gt; <a href="?package=async_unix&amp;module=Scheduler&amp;type=t">t</a> -&gt; (<a href="?package=async_unix&amp;module=Scheduler&amp;type=t">t</a>, 'a) <a href="?package=core&amp;module=Std.Field&amp;type=t">Core.Std.Field.t</a> -&gt; 'b</code>;</code></td></tr><tr><td>}</td></tr></table><div class="info"><div class="info"><code class="code">fold_fields ~init folder</code> folds <code class="code">folder</code> over each field in the scheduler.  The
    fields themselves are not exposed -- <code class="code">folder</code> must be a polymorphic function that
    can work on any field.  So, it's only useful for generic operations, e.g. getting
    the size of each field.</div></div>
<pre><span class="VALfold_fields"><span class="keyword">val</span> fold_fields</span> : <code class="type">init:'b -&gt; 'b <a href="?package=async_unix&amp;module=Scheduler&amp;type=folder">folder</a> -&gt; 'b</code></pre>
<pre><span class="VALis_ready_to_initialize"><span class="keyword">val</span> is_ready_to_initialize</span> : <code class="type">unit -&gt; bool</code></pre>
<pre><span class="VALreset_in_forked_process"><span class="keyword">val</span> reset_in_forked_process</span> : <code class="type">unit -&gt; unit</code></pre><div class="info"><div class="info">If a process that has already created, but not started, the async scheduler would like
    to fork, and would like the child to have a clean async, i.e. not inherit any of the
    async work that was done in the parent, it can call <code class="code">reset_in_forked_process</code> at the
    start of execution in the child process.  After that, the child can do async stuff and
    then start the async scheduler.</div></div>
<pre><span class="VALadd_busy_poller"><span class="keyword">val</span> add_busy_poller</span> : <code class="type">(unit -&gt; [ `Continue_polling | `Stop_polling of 'a ]) -&gt; 'a <a href="?package=async_unix&amp;module=Import.Deferred&amp;type=t">Import.Deferred.t</a></code></pre><div class="info"><div class="info">Async supports &quot;busy polling&quot;, which runs a thread that busy loops running
    user-supplied polling functions.  The busy-loop thread is distinct from async's
    scheduler thread.<p>    Busy polling is useful for a situation like a shared-memory ringbuffer being used for
    IPC.  One can poll the ringbuffer with a busy poller, and then when data is detected,
    fill some ivar that causes async code to handle the data.</p><p>    <code class="code">add_busy_poller poll</code> adds <code class="code">poll</code> to the busy loop.  <code class="code">poll</code> will be called
    continuously, once per iteration of the busy loop, until it returns <code class="code">`Stop_polling a</code>
    at which point the result of <code class="code">add_busy_poller</code> will become determined.  <code class="code">poll</code> will
    hold the async lock while running, so it is fine to do ordinary async operations,
    e.g. fill an ivar.  The busy loop will run an ordinary async cycle if any of the
    pollers add jobs.</p><p>    <code class="code">poll</code> will run in monitor in effect when <code class="code">add_busy_poller</code> was called; exceptions
    raised by <code class="code">poll</code> will be sent asynchronously to that monitor.  If <code class="code">poll</code> raises, it
    will still be run on subsequent iterations of the busy loop.</p></div></div>
<pre><span class="VALhandle_thread_pool_stuck"><span class="keyword">val</span> handle_thread_pool_stuck</span> : <code class="type">(<a href="?package=core&amp;module=Std.Time.Span&amp;type=t">Core.Std.Time.Span.t</a> -&gt; unit) -&gt; unit</code></pre><div class="info"><div class="info"><code class="code">handle_thread_pool_stuck f</code> causes <code class="code">f</code> to run whenever async detects its thread pool
    is stuck (i.e. hasn't completed a job for over a second and has no available threads).
    Async checks every second.  By default, if thread pool has been stuck for less than
    60s, async will <code class="code">eprintf</code> a message.  If more than 60s, async will send an exception
    to the main monitor, which will abort the program unless there is a custom handler for
    the main monitor.<p>    Calling <code class="code">handle_thread_pool_stuck</code> replaces whatever behavior was previously there.</p></div></div>
<pre><span class="VALsexp_of_t"><span class="keyword">val</span> sexp_of_t</span> : <code class="type"><a href="?package=async_unix&amp;module=Scheduler&amp;type=t">t</a> -&gt; <a href="?package=sexplib&amp;module=Sexp&amp;type=t">Sexplib.Sexp.t</a></code></pre>
<div class="info"><div class="info"><code class="code">t ()</code> returns the async scheduler.  If the scheduler hasn't been created yet, this
    will create it and acquire the async lock.</div></div>
<div class="info"><div class="info"><code class="code">go ?raise_unhandled_exn ()</code> passes control to Async, at which point Async starts
    running handlers, one by one without interruption, until there are no more handlers to
    run.  When Async is out of handlers it blocks until the outside world schedules more
    of them.  Because of this, Async programs do not exit until <code class="code">shutdown</code> is called.<p>    <code class="code">go ()</code> calls <code class="code">handle_signal Sys.sigpipe</code>, which causes the SIGPIPE signal to be
    ignored.  Low-level syscalls (e.g. write) still raise EPIPE.</p><p>    If any async job raises an unhandled exception that is not handled by any monitor,
    async execution ceases.  Then, by default, async pretty prints the exception, and
    exits with status 1.  If you don't want this, pass <code class="code">~raise_unhandled_exn:true</code>, which
    will cause the unhandled exception to be raised to the caller of <code class="code">go ()</code>.</p></div></div>
<div class="info"><div class="info">default is <code class="code">false</code></div></div>
<div class="info"><div class="info"><code class="code">go_main</code> is like <code class="code">go</code>, except that one supplies a <code class="code">main</code> function that will be run to
    initialize the async computation, and that <code class="code">go_main</code> will fail if any async has been
    used prior to <code class="code">go_main</code> being called.  Moreover it allows to configure more static
    options of the scheduler.</div></div>
<div class="info"><div class="info">default is <code class="code">false</code></div></div>
<div class="info"><div class="info">default to <code class="code">Config</code></div></div>
<div class="info"><div class="info">default to <code class="code">Config</code></div></div>
<div class="info"><div class="info">default to <code class="code">Config</code></div></div>
<div class="info"><div class="info"><code class="code">within_context context f</code> runs <code class="code">f ()</code> right now with the specified execution
    context.  If <code class="code">f</code> raises, then the exception is sent to the monitor of <code class="code">context</code>, and
    <code class="code">Error ()</code> is returned.</div></div>
<div class="info"><div class="info"><code class="code">within' f ~monitor ~priority</code> runs <code class="code">f ()</code> right now, with the specified
    block group, monitor, and priority set as specified.  They will be reset to their
    original values when <code class="code">f</code> returns.  If <code class="code">f</code> raises, then the result of <code class="code">within'</code> will
    never become determined, but the exception will end up in the specified monitor.</div></div>
<div class="info"><div class="info"><code class="code">within</code> is like <code class="code">within'</code>, but doesn't require thunk to return a deferred.</div></div>
<div class="info"><div class="info"><code class="code">within_v</code> is like <code class="code">within</code>, but allows a value to be returned by <code class="code">f</code>.</div></div>
<div class="info"><div class="info"><code class="code">with_local key value ~f</code> runs <code class="code">f</code> right now with the binding <code class="code">key = value</code>.  All
    calls to <code class="code">find_local key</code> in <code class="code">f</code> and computations started from <code class="code">f</code> will return
    <code class="code">value</code>.</div></div>
<div class="info"><div class="info"><code class="code">find_local key</code> returns the value associated to <code class="code">key</code> in the current execution
    context.</div></div>
<div class="info"><div class="info">Just like <code class="code">within'</code>, but instead of running thunk right now, adds
    it to the async queue to be run with other async jobs.</div></div>
<div class="info"><div class="info">Just like schedule', but doesn't require thunk to return a deferred.</div></div>
<div class="info"><div class="info"><code class="code">preserve_execution_context t f</code> saves the current execution context and returns a
    function <code class="code">g</code> such that <code class="code">g a</code> runs <code class="code">f a</code> in the saved execution context.  <code class="code">g a</code> becomes
    determined when <code class="code">f a</code> becomes determined.</div></div>
<div class="info"><div class="info"><code class="code">cycle_start ()</code> returns the result of <code class="code">Time.now ()</code> called at the beginning of
    cycle.</div></div>
<div class="info"><div class="info"><code class="code">cycle_times ()</code> returns a stream that will have one element for each cycle that Async
    runs, with the amount of time that the cycle took (as determined by calls to Time.now
    at the beginning and end of the cycle).</div></div>
<div class="info"><div class="info"><code class="code">report_long_cycle_times ?cutoff ()</code> sets up something that will print a warning to
    stderr whenever there is an async cycle that is too long, as specified by <code class="code">cutoff</code>,
    whose default is 1s.</div></div>
<div class="info"><div class="info"><code class="code">cycle_count ()</code> returns the total number of async cycles that have happened.</div></div>
<div class="info"><div class="info"><code class="code">force_current_cycle_to_end ()</code> causes no more normal priority jobs to run in the
    current cycle, and for the end-of-cycle jobs (i.e. writes) to run, and then for the
    cycle to end.</div></div>
<div class="info"><div class="info"><code class="code">is_running ()</code> returns true if the scheduler has been started.</div></div>
<div class="info"><div class="info"><code class="code">set_max_num_jobs_per_priority_per_cycle int</code> sets the maximum number of jobs that
    will be done at each priority within each async cycle.  The default is <code class="code">500</code>.</div></div>
<div class="info"><div class="info"><code class="code">set_max_inter_cycle_timeout span</code> sets the maximum amount of time the scheduler will
    remain blocked (on epoll or select) between cycles.</div></div>
<div class="info"><div class="info"><code class="code">set_check_invariants do_check</code> sets whether async should check invariants of its
    internal data structures.  <code class="code">set_check_invariants true</code> can substantially slow down
    your program.</div></div>
<div class="info"><div class="info"><code class="code">set_detect_invalid_access_from_thread do_check</code> sets whether async routines should
    check if they are being accessed from some thread other than the thread currently
    holding the async lock, which is not allowed and can lead to very confusing
    behavior.</div></div>
<div class="info"><div class="info"><code class="code">set_record_backtraces do_record</code> sets whether async should keep in the execution
    context the history of stack backtraces (obtained via <code class="code">Backtrace.get</code>) that led to the
    current job.  If an async job has an unhandled exception, this backtrace history will
    be recorded in the exception.  In particular the history will appean in an unhandled
    exception that reaches the main monitor.  This can have a substantial performance
    impact, both in running time and space usage.</div></div>
<div class="info"><div class="info"><code class="code">fold_fields ~init folder</code> folds <code class="code">folder</code> over each field in the scheduler.  The
    fields themselves are not exposed -- <code class="code">folder</code> must be a polymorphic function that
    can work on any field.  So, it's only useful for generic operations, e.g. getting
    the size of each field.</div></div>
<div class="info"><div class="info">If a process that has already created, but not started, the async scheduler would like
    to fork, and would like the child to have a clean async, i.e. not inherit any of the
    async work that was done in the parent, it can call <code class="code">reset_in_forked_process</code> at the
    start of execution in the child process.  After that, the child can do async stuff and
    then start the async scheduler.</div></div>
<div class="info"><div class="info">Async supports &quot;busy polling&quot;, which runs a thread that busy loops running
    user-supplied polling functions.  The busy-loop thread is distinct from async's
    scheduler thread.<p>    Busy polling is useful for a situation like a shared-memory ringbuffer being used for
    IPC.  One can poll the ringbuffer with a busy poller, and then when data is detected,
    fill some ivar that causes async code to handle the data.</p><p>    <code class="code">add_busy_poller poll</code> adds <code class="code">poll</code> to the busy loop.  <code class="code">poll</code> will be called
    continuously, once per iteration of the busy loop, until it returns <code class="code">`Stop_polling a</code>
    at which point the result of <code class="code">add_busy_poller</code> will become determined.  <code class="code">poll</code> will
    hold the async lock while running, so it is fine to do ordinary async operations,
    e.g. fill an ivar.  The busy loop will run an ordinary async cycle if any of the
    pollers add jobs.</p><p>    <code class="code">poll</code> will run in monitor in effect when <code class="code">add_busy_poller</code> was called; exceptions
    raised by <code class="code">poll</code> will be sent asynchronously to that monitor.  If <code class="code">poll</code> raises, it
    will still be run on subsequent iterations of the busy loop.</p></div></div>
<div class="info"><div class="info"><code class="code">handle_thread_pool_stuck f</code> causes <code class="code">f</code> to run whenever async detects its thread pool
    is stuck (i.e. hasn't completed a job for over a second and has no available threads).
    Async checks every second.  By default, if thread pool has been stuck for less than
    60s, async will <code class="code">eprintf</code> a message.  If more than 60s, async will send an exception
    to the main monitor, which will abort the program unless there is a custom handler for
    the main monitor.<p>    Calling <code class="code">handle_thread_pool_stuck</code> replaces whatever behavior was previously there.</p></div></div>
</div>