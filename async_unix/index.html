<h1>Modules</h1>
<table class="indextable">
    <tr><td class="module"><a href="?package=async_unix&amp;module=Async_print">Async_print</a></td><td><div class="info">Non-blocking, Async-friendly print functions</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Async_sys">Async_sys</a></td><td><div class="info">This module overrides everything in the <code class="code">Sys</code> module that might block.  Functions do
    the same thing as their counterparts in <code class="code">Sys</code>, but instead return deferreds.  For a
    description of the semantics of their semantics see the documentation for the <code class="code">Sys</code>
    module.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Busy_pollers">Busy_pollers</a></td><td><div class="info">A set of busy-poll functions.<br/>    See  <a href="#Scheduler.add_busy_poller">Scheduler.add_busy_poller</a> for the user-level interface.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Epoll_file_descr_watcher">Epoll_file_descr_watcher</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Fd">Fd</a></td><td><div class="info">An <code class="code">Fd.t</code> is a wrapper around a Unix file descriptor, with additional information
    about the kind of file descriptor and logic to ensure that we don't use a file
    descriptor that has been closed, or close a file descriptor that is in use.  Since
    Async uses multiple threads to make read/write and other system calls on file
    descriptors, and Unix reuses descriptors after they are closed, Async has to be very
    careful that the file descriptor passed to a system call is referring to the file it
    intends, and not some other completely unrelated file that Unix has decided to assign
    to the same descriptor.<br/>    Provided that one only accesses a file descriptor within the context of the functions
    below, <code class="code">Fd</code> guarantees that the file descriptor will not have been closed/reused and
    will correspond to the same file that it did when the <code class="code">Fd.t</code> was created:<br/>    <span class="verbatim">      with_file_descr
      with_file_descr_deferred
      syscall
      syscall_exn
      syscall_in_thread
      syscall_in_thread_exn
    </span><br/>    The <code class="code">Fd</code> module keeps track of which of these functions that are currently accessing
    the file descriptor, and ensures that any close happens after they complete.  Also,
    once close has been called, it refuses to provide further access to the file
    descriptor, either by returning a variant, `Already_closed, or raising an exception.<br/>    Some of the above functions take an optional <code class="code">?nonblocking:bool</code> argument.  The
    default is <code class="code">false</code>, but if it is set to true, then before supplying the underlying
    <code class="code">file_descr</code>, the <code class="code">Fd</code> module will first call <code class="code">Unix.set_nonblock file_descr</code>, if it
    hasn't previously done so on that file descriptor.  This is intended to support making
    nonblocking system calls (e.g. connect, read, write) directly within async, without
    releasing the OCaml lock or the async lock, and without using another thread.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Fd_by_descr">Fd_by_descr</a></td><td><div class="info"><code class="code">Fd_by_descr</code> is a table of the open <code class="code">Fd.t</code>s, indexed by file descriptor number.<br/>    In this interface, we use <code class="code">Raw_fd.t</code> rather than <code class="code">Fd.t</code> to avoid a dependency cycle,
    because the <code class="code">Fd</code> module can't be defined yet.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=File_descr_watcher_intf">File_descr_watcher_intf</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Import">Import</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=In_thread">In_thread</a></td><td><div class="info">The <code class="code">In_thread</code> module has functions for interaction between the Async world and other
    (kernel) threads.  The name is to remind us to think about threads and race
    conditions.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Interruptor">Interruptor</a></td><td><div class="info">An interruptor provides a file descriptor that can be used to cause a
    file-descr-watcher to detect the file descriptor is ready for reading.  We use an
    interruptor when a thread needs the async scheduler to service a request.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Io_stats">Io_stats</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Process">Process</a></td><td><div class="info"><code class="code">Async.Process</code> is for creating child processes of the current process, and
    communicating with children via their stdin, stdout, and stderr.  <code class="code">Async.Process</code> is
    the async analog of <code class="code">Core.Unix.create_process</code> and related functions.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Raw_fd">Raw_fd</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Raw_scheduler">Raw_scheduler</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Raw_signal_manager">Raw_signal_manager</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Read_write">Read_write</a></td><td><div class="info"><code class="code">Read_write</code> is like <code class="code">Dirpair</code>, except &quot;buy/sell&quot; has been changed to &quot;read/write&quot;.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Reader">Reader</a></td><td><div class="info"><code class="code">Reader</code> is Async's main API for buffered input from a file descriptor.  It is the
    analog of <code class="code">Core.Std.In_channel</code>.<br/>    Each reader has an internal buffer, which is filled via <code class="code">read()</code> system calls when
    data is needed to satisfy a <code class="code">Reader.read*</code> call.<br/>    Each of the read functions returns a deferred that will become determined when the
    read completes.  It is an error to have two simultaneous reads.  That is, if one calls
    a read function, one should not call another read function until the first one
    completes.<br/>    If the file descriptor underlying a reader is closed, the reader will return EOF
    (after all the buffered bytes have been read).<br/>    Any <code class="code">Reader.read*</code> call could, rather than determine its result, send an exception to
    the monitor in effect when <code class="code">read</code> was called.  Such exceptions can be handled in the
    usual way by using <code class="code">try_with</code>, e.g.:<br/>    <pre class="codepre"><code class="code">
      try_with (fun () -&gt; Reader.read reader ...)
    </code></pre></div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Reader0">Reader0</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Scheduler">Scheduler</a></td><td><div class="info">Threading model:<br/>    Only one thread is running Async code at a time.  This is enforced by a single lock in
    Async's scheduler data structure.  There are any number of threads running code
    without holding the lock that get data from the outside world and want to affect the
    Async world.  They do this by calling <code class="code">Thread_safe.run_in_async*</code>, which acquires the
    lock, does a computation (e.g. fills an ivar), and then runs a &quot;cycle&quot; of Async
    computations.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Select_file_descr_watcher">Select_file_descr_watcher</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Shutdown">Shutdown</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Signal">Signal</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Signal_manager">Signal_manager</a></td><td><div class="info">A signal manager keeps track of a set of signals to be managed and the signal handlers
    for them.  When a signal manager is managing a signal, it installs its own OCaml
    handler for that signal that records delivery of the signal.  It then later, upon
    request, will deliver the signal to all its handlers.<br/>    Once a signal manager starts managing a signal, it never stops.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Std">Std</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Syscall">Syscall</a></td><td/></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Thread_pool">Thread_pool</a></td><td><div class="info">A thread pool is a set of OCaml threads used to do work, where each piece of work is
    simply a thunk.  One creates a thread pool, and then uses <code class="code">add_work</code> to submit work to
    it.  Work is done first-come-first-served by available threads in the pool.  Any of
    the available threads in the pool could be used to do work submitted to the pool
    (except helper threads, see below).<br/>    A thread pool starts with no threads.  As work is added, the thread pool creates new
    threads to do the work, up to the maximum number of allowed threads,
    <code class="code">max_num_threads</code>, supplied to <code class="code">create</code>.  Thread-pool threads never die.  They just
    get created up until <code class="code">max_num_threads</code> is reached and then live forever, doing work.
    Each thread in the pool is in a loop, waiting for a piece of work, running the thunk,
    and then repeating.  It may be that all the threads in the pool are not doing
    anything, but in this case, the threads still exist, and are simply blocked waiting
    for work.<br/>    Sometimes one wants work to run in a dedicated thread, e.g. some C libraries require
    this.  To do this, use <code class="code">Helper_thread</code>, see below.<br/>    All of the functions exposed by this module are thread safe; they synchronize using
    a mutex on the thread pool.<br/>    One can control the priority of threads in the pool (in the sense of
    <code class="code">Linux_ext.setpriority</code>).  Work added to the pool can optionally be given a priority,
    and the pool will set the priority of the thread that runs it for the duration of the
    work.  Helper threads can also be given a priority, which will be used for all work
    run by the helper thread, unless the work has an overriding priority.  The thread pool
    has a &quot;default&quot; priority that will be used for all work and helper threads that have
    no specified priority.  The default is simply the priority in effect when <code class="code">create</code> is
    called.<br/>    Behavior is unspecified if work calls <code class="code">setpriority</code> directly.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Thread_safe">Thread_safe</a></td><td><div class="info">The <code class="code">Thread_safe</code> module has functions that are safe to call from threads outside
    async.<br/>    All the <code class="code">Thread_safe.block*</code> and <code class="code">Thread_safe.run*</code> functions wake up the async
    scheduler to ensure that it continues in a timely manned with whatever jobs got
    started.  Some functions take an optional <code class="code">?wakeup_scheduler:bool</code> argument, which
    defaults to <code class="code">true</code>.  One can cause the scheduler to not be woken up by supplying
    <code class="code">~wakeup_scheduler:false</code>, which can reduce CPU use, but increase latency, because the
    scheduler may not wake up for a while to process jobs.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Thread_safe_pipe">Thread_safe_pipe</a></td><td><div class="info">A thread-safe pipe is a thread-safe interface to the write end of a normal
    <code class="code">Async.Pipe</code>.  All operations except for <code class="code">create</code> must be called from threads outside
    async.  <code class="code">create</code> can be called from inside or outside async.<br/>    For <code class="code">Pipe</code> functions that return a <code class="code">unit Deferred.t</code>, the analog in <code class="code">Thread_safe_pipe</code>
    blocks.<br/>    For documentation of <code class="code">wakeup_scheduler</code>, see the  <a href="#Thread_safe">Thread_safe</a> module.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Unix_syscalls">Unix_syscalls</a></td><td><div class="info"><code class="code">Unix_syscalls</code> provides an interface to many of the functions in OCaml's standard
    Unix module.  It uses a deferred in the return type of functions that would block.
    The idea is that in an async program one does not use the standard Unix module, since
    in doing so one could accidentally block the whole program.<br/>    There are also a number of cosmetic changes (e.g. polymorphic variants) and other
    improvements (e.g. phantom types on sockets) over the standard Unix module.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Writer">Writer</a></td><td><div class="info"><code class="code">Writer</code> is Async's main API for output to a file descriptor.  It is the analog of
    <code class="code">Core.Std.Out_channel</code>.<br/>    Each writer has an internal buffer, to which <code class="code">Writer.write*</code> adds data.  Each writer
    uses an async microthread that makes <code class="code">write()</code> system calls to move the data from the
    writer's buffer to an OS buffer via the file descriptor.  There is no guarantee that
    the data sync on the other side of the writer can keep up with the rate at which you
    are writing.  If it cannot, the OS buffer will fill up and the writer's micro-thread
    will be unable to send any bytes.  In that case, calls to <code class="code">Writer.write*</code> will grow
    the writer's buffer without bound, as long as your program produces data.  One
    solution to this problem is to call <code class="code">Writer.flushed</code> and not continue until that
    becomes determined, which will only happen once the bytes in the writer's buffer have
    been successfully transferred to the OS buffer.  Another solution is to check
    <code class="code">Writer.bytes_to_write</code> and not produce any more data if that is beyond some bound.<br/>    There are two kinds of errors that one can handle with writers.  First, a writer can
    be <code class="code">close</code>d, which will cause future <code class="code">write</code>s (and other operations) to synchronously
    raise an excecption.  Second, the writer's microthread can fail due to a <code class="code">write()</code>
    system call failing.  This will cause an exception to be sent to the writer's monitor,
    which will be a child of the monitor in effect when the writer is created.  One can
    deal with such asynchronous exceptions in the usual way, by handling the stream
    returned by <code class="code">Monitor.errors (Writer.monitor writer)</code>.</div></td></tr>
<tr><td class="module"><a href="?package=async_unix&amp;module=Writer0">Writer0</a></td><td/></tr>
</table>